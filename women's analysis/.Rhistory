?cut_number
??cut_number
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
library(tidyverse)
library(tidyverse)
library(tidySEM)
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
fit_measures_f <- read.csv("./fit_measures_females.csv")  %>% select(-n_parameters.1)
#Transform na into 0.
replace_0 <- rep_len(0, 8) %>% as.list()
names(replace_0)<-colnames(p_f)   #Replace NA with 0 in the whole dataframe
p_f <- replace_na(p_f, replace_0)
#Get get the predicted class-membership
p_f <- p_f %>% mutate(pred_class = map_dbl(1:nrow(p_f),~p_f %>% select(-n_classes) %>% slice(.x) %>% which.max()))
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
fit_measures_f <- read.csv("./fit_measures_females.csv")  %>% select(-n_parameters.1)
#Transform na into 0.
replace_0 <- rep_len(0, 8) %>% as.list()
names(replace_0)<-colnames(p_f)   #Replace NA with 0 in the whole dataframe
p_f <- replace_na(p_f, replace_0)
#Get get the predicted class-membership
p_f <- p_f %>% mutate(pred_class = map_dbl(1:nrow(p_f),~p_f %>% select(-n_classes) %>% slice(.x) %>% which.max()))
#Get n_min and insert it o the fit_measures_f data_frame
fit_measures_f <- fit_measures_f %>%
mutate(n_min = p_f %>% #take the probabilities frame
group_by(n_classes, pred_class) %>%                                               summarise(n_min = n()/1263) %>% #see how big relative to n each class in each model is
ungroup() %>%
group_by(n_classes) %>%
slice_min(n_min) %>% #return the size value of the smallest class in each model
pull(n_min))
#| label: bootstrapped_data
#read in the data
bootstrapped_params_f <- read_csv("bootstrapped_samples_k3.csv") %>% select(-rep)
sm_params_m <- read_csv("parameters_males_k3.csv") %>%
filter(model == "structural") %>%
select(variable, value, class_no) %>%
pivot_wider(values_from = value,
names_from = class_no,
names_glue = "class{class_no}_parameter")
#| label: bootstrapped_data
#read in the data
bootstrapped_params_f <- read_csv("bootstrapped_samples_k3.csv") %>% select(-rep)
sm_params_m <- read_csv("parameters_females_k3.csv") %>%
filter(model == "structural") %>%
select(variable, value, class_no) %>%
pivot_wider(values_from = value,
names_from = class_no,
names_glue = "class{class_no}_parameter")
#select the structural parameters
sm_boot_params_f <- bootstrapped_params_f %>%
filter(model == "structural") %>%
select(class_no, variable, value)
#summarise CIs
sm_CIs_f <- sm_boot_params_f %>%
select(class_no, variable, value) %>%
group_by(class_no, variable)  %>%
summarise(LB_0.025 = quantile(value, probs = c(0.025, 0.975))[1],
UB_0.975 = quantile(value, probs = c(0.025, 0.975))[2]) %>%
ungroup()
#Pivot dataframe for convenience reading, join with the sm_params_m tibble & compute significance decisions. Significance decisions are based on the dichotomous nature of the outcomes. If the 95 % CI of the parameters encloses 0.5, than the membership of that class tells us nothing about the propensity of a person to give a propensity other than zero.
sm_CIs_f <- sm_CIs_f %>%
pivot_wider(values_from = c(LB_0.025, UB_0.975), #pivot dataframe
names_from = class_no,
names_glue = "class{class_no}_{.value}") %>%
full_join(sm_params_m, by= "variable") %>% #join with the actual estimated parameter values
mutate(class0_sig = case_when((class0_LB_0.025 > 0.5) |                                    (0.5 > class0_UB_0.975) ~ "significant",
.default = "not_significant" ), #significance class 0
class1_sig = case_when((class1_LB_0.025 > 0.5) |                                    (0.5 > class1_UB_0.975) ~ "significant",
.default = "not_significant"), #significance class 1
class2_sig = case_when((class2_LB_0.025 > 0.5) |                                    (0.5 > class2_UB_0.975) ~ "significant",
.default = "not_significant" )) %>% #significance class 2
relocate(variable, contains("class0"), contains("class1"), contains("class2")) #nicely order the dataframe
#| label: CI_mixture_f
#compute 95% CI for mixture parameters
CI_mixture_f <- bootstrapped_params_f %>%
filter(model_name == "class_weights") %>% #filter mixture parameters
select(class_no, value) %>% #select necessary variables
group_by(class_no) %>% #group_by classes
summarise(LB = quantile(value, probs=c(0.025, 0.975))[1], #get bounds of CIs
UB = quantile(value, probs=c(0.025, 0.975))[2])
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/women's analysis/.RData")
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/women's analysis/.RData")
View(CI_mixture_f)
View(fit_measures_f)
View(sm_boot_params_f)
View(sm_CIs_f)
#load the data
cp_posts <- read_csv("A:/child_posts_clean.csv)
#load the data
cp_posts <- read_csv("A:/child_posts_clean.csv")
View(cp_posts)
#load the data
cp_posts <- read_csv("A:/child_posts_clean.csv") %>% select(pid, uid, tid, fid, subject, message, dateline)
View(cp_posts)
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote.*?\\[/quote\\]")) %>% view()
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote*?\\[/quote\\]")) %>% view()
df <- data.frame(message = c("[quote]Hello, world![/quote]", "Some text [quote]with[/quote] quotes"))
View(df)
df_cleaned <- df %>%
mutate(message = str_remove_all(message, "\\[quote\\].*?\\[/quote\\]"))
View(df_cleaned)
View(df)
View(df)
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote*\\[/quote\\]")) %>% view()
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote=*quote\\]")) %>% view()
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote=*//[/quote\\]")) %>% view()
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote=*\\[/quote\\]")) %>% view()
cp_posts %>% mutate(message = str_remove_all(message, "\\[quote=[^\\]]+\\].*?\\[/quote\\]")) %>% view()
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
fit_measures_f <- read.csv("./fit_measures_females.csv")  %>% select(-n_parameters.1)
#Transform na into 0.
replace_0 <- rep_len(0, 8) %>% as.list()
names(replace_0)<-colnames(p_f)   #Replace NA with 0 in the whole dataframe
p_f <- replace_na(p_f, replace_0)
#Get get the predicted class-membership
p_f <- p_f %>% mutate(pred_class = map_dbl(1:nrow(p_f),~p_f %>% select(-n_classes) %>% slice(.x) %>% which.max()))
#Get n_min and insert it o the fit_measures_f data_frame
fit_measures_f <- fit_measures_f %>%
mutate(n_min = p_f %>% #take the probabilities frame
group_by(n_classes, pred_class) %>%                                               summarise(n_min = n()/1263) %>% #see how big relative to n each class in each model is
ungroup() %>%
group_by(n_classes) %>%
slice_min(n_min) %>% #return the size value of the smallest class in each model
pull(n_min))
fit_measures_f <- fit_measures_f %>% mutate(np_ratio = 1263/n_parameters)
#| label: bootstrapped_data
#read in the data
bootstrapped_params_f <- read_csv("bootstrapped_samples_k3.csv") %>% select(-rep)
sm_params_f <- read_csv("parameters_females_k3.csv") %>%
filter(model == "structural") %>%
select(variable, value, class_no) %>%
pivot_wider(values_from = value,
names_from = class_no,
names_glue = "class{class_no}_parameter")
#select the structural parameters
sm_boot_params_f <- bootstrapped_params_f %>%
filter(model == "structural") %>%
select(class_no, variable, value)
#summarise CIs
sm_CIs_f <- sm_boot_params_f %>%
select(class_no, variable, value) %>%
group_by(class_no, variable)  %>%
summarise(LB_0.025 = quantile(value, probs = c(0.025, 0.975))[1],
UB_0.975 = quantile(value, probs = c(0.025, 0.975))[2]) %>%
ungroup()
#Pivot dataframe for convenience reading, join with the sm_params_m tibble & compute significance decisions. Significance decisions are based on the dichotomous nature of the outcomes. If the 95 % CI of the parameters encloses 0.5, than the membership of that class tells us nothing about the propensity of a person to give a propensity other than zero.
sm_CIs_f <- sm_CIs_f %>%
pivot_wider(values_from = c(LB_0.025, UB_0.975), #pivot dataframe
names_from = class_no,
names_glue = "class{class_no}_{.value}") %>%
full_join(sm_params_m, by= "variable") %>% #join with the actual estimated parameter values
mutate(class0_sig = case_when((class0_LB_0.025 > 0.5) |                                    (0.5 > class0_UB_0.975) ~ "significant",
.default = "not_significant" ), #significance class 0
class1_sig = case_when((class1_LB_0.025 > 0.5) |                                    (0.5 > class1_UB_0.975) ~ "significant",
.default = "not_significant"), #significance class 1
class2_sig = case_when((class2_LB_0.025 > 0.5) |                                    (0.5 > class2_UB_0.975) ~ "significant",
.default = "not_significant" )) %>% #significance class 2
relocate(variable, contains("class0"), contains("class1"), contains("class2")) #nicely order the dataframe
#Pivot dataframe for convenience reading, join with the sm_params_m tibble & compute significance decisions. Significance decisions are based on the dichotomous nature of the outcomes. If the 95 % CI of the parameters encloses 0.5, than the membership of that class tells us nothing about the propensity of a person to give a propensity other than zero.
sm_CIs_f <- sm_CIs_f %>%
pivot_wider(values_from = c(LB_0.025, UB_0.975), #pivot dataframe
names_from = class_no,
names_glue = "class{class_no}_{.value}") %>%
full_join(sm_params_f, by= "variable") %>% #join with the actual estimated parameter values
mutate(class0_sig = case_when((class0_LB_0.025 > 0.5) |                                    (0.5 > class0_UB_0.975) ~ "significant",
.default = "not_significant" ), #significance class 0
class1_sig = case_when((class1_LB_0.025 > 0.5) |                                    (0.5 > class1_UB_0.975) ~ "significant",
.default = "not_significant"), #significance class 1
class2_sig = case_when((class2_LB_0.025 > 0.5) |                                    (0.5 > class2_UB_0.975) ~ "significant",
.default = "not_significant" )) %>% #significance class 2
relocate(variable, contains("class0"), contains("class1"), contains("class2")) #nicely order the dataframe
#| label: CI_mixture_f
#compute 95% CI for mixture parameters
CI_mixture_f <- bootstrapped_params_f %>%
filter(model_name == "class_weights") %>% #filter mixture parameters
select(class_no, value) %>% #select necessary variables
group_by(class_no) %>% #group_by classes
summarise(LB = quantile(value, probs=c(0.025, 0.975))[1], #get bounds of CIs
UB = quantile(value, probs=c(0.025, 0.975))[2])
#Point estimates for OddsRatios
OR_f <- sm_params_f %>%
rename("social"="class0_parameter", "mating" ="class1_parameter", "multiple"="class2_parameter") %>%
mutate(across(all_of(c("social", "mating", "multiple")), ~.x/(1-.x), .names = "Odds_{col}")) %>%
mutate(OR_multiple_mating = Odds_multiple/Odds_mating,
OR_multiple_social = Odds_multiple/Odds_social,
OR_mating_social = Odds_mating/Odds_social) %>%
select(variable, starts_with("OR"))
#Bootstrapped CIs for Odds Ratios
CI_OR_f <- sm_boot_params_f %>%
mutate(boot_id = rep(1:500,sm_boot_params_f %>%
select(class_no, variable) %>%
n_distinct()), #create an id column that makes it possibel to find every bootstrapping iteration
odds = value/(1-value)) %>% #compute odds from the probability values
select(-value) %>%
pivot_wider(names_from = class_no, values_from = odds) %>% #get a wider dataframe for OR computations
rename(social="0", mating ="1", multiple="2") %>% #rename columns for better understanding
mutate(OR_multiple_mating = multiple/mating, #compute ORs for each bootstrap iteration
OR_multiple_social = multiple/social,
OR_mating_social = mating/social) %>%
select(variable, starts_with("OR")) %>%
group_by(variable) %>% #group by each outcome variable & compute upper and lower limits for each confidence interval
summarise(across(starts_with("OR"),~quantile(.x, probs=c(0.025, 0.975))[1], .names = "LB_{col}"),
across(starts_with("OR"),~quantile(.x, probs=c(0.025, 0.975))[2], .names = "UB_{col}"))
View(CI_OR_f)
options(scipen=999)
View(CI_OR_f)
library(tidyverse)
#Point estimates for OddsRatios
OR_f <- sm_params_f %>%
rename("social"="class0_parameter", "mating" ="class1_parameter", "multiple"="class2_parameter") %>%
mutate(across(all_of(c("social", "mating", "multiple")), ~.x/(1-.x), .names = "Odds_{col}")) %>%
mutate(OR_multiple_mating = Odds_multiple/Odds_mating,
OR_multiple_social = Odds_multiple/Odds_social,
OR_mating_social = Odds_mating/Odds_social) %>%
select(variable, starts_with("OR"))
#Import the predicted class memberships csv
p_f <- read_csv("posterior_class_probs_females.csv")[,-1] %>% select(n_classes, matches("[[:digit:]]"))
fit_measures_f <- read.csv("./fit_measures_females.csv")  %>% select(-n_parameters.1)
#Transform na into 0.
replace_0 <- rep_len(0, 8) %>% as.list()
names(replace_0)<-colnames(p_f)   #Replace NA with 0 in the whole dataframe
p_f <- replace_na(p_f, replace_0)
#Get get the predicted class-membership
p_f <- p_f %>% mutate(pred_class = map_dbl(1:nrow(p_f),~p_f %>% select(-n_classes) %>% slice(.x) %>% which.max()))
#Get n_min and insert it o the fit_measures_f data_frame
fit_measures_f <- fit_measures_f %>%
mutate(n_min = p_f %>% #take the probabilities frame
group_by(n_classes, pred_class) %>%                                               summarise(n_min = n()/1420) %>% #see how big relative to n each class in each model is
ungroup() %>%
group_by(n_classes) %>%
slice_min(n_min) %>% #return the size value of the smallest class in each model
pull(n_min))
fit_measures_f <- fit_measures_f %>% mutate(np_ratio = 1263/n_parameters)
#| label: bootstrapped_data
#read in the data
bootstrapped_params_f <- read_csv("bootstrapped_samples_k3.csv") %>% select(-rep)
sm_params_f <- read_csv("parameters_females_k3.csv") %>%
filter(model == "structural") %>%
select(variable, value, class_no) %>%
pivot_wider(values_from = value,
names_from = class_no,
names_glue = "class{class_no}_parameter")
#select the structural parameters
sm_boot_params_f <- bootstrapped_params_f %>%
filter(model == "structural") %>%
select(class_no, variable, value)
#summarise CIs
sm_CIs_f <- sm_boot_params_f %>%
select(class_no, variable, value) %>%
group_by(class_no, variable)  %>%
summarise(LB_0.025 = quantile(value, probs = c(0.025, 0.975))[1],
UB_0.975 = quantile(value, probs = c(0.025, 0.975))[2]) %>%
ungroup()
#Pivot dataframe for convenience reading, join with the sm_params_m tibble & compute significance decisions. Significance decisions are based on the dichotomous nature of the outcomes. If the 95 % CI of the parameters encloses 0.5, than the membership of that class tells us nothing about the propensity of a person to give a propensity other than zero.
sm_CIs_f <- sm_CIs_f %>%
pivot_wider(values_from = c(LB_0.025, UB_0.975), #pivot dataframe
names_from = class_no,
names_glue = "class{class_no}_{.value}") %>%
full_join(sm_params_f, by= "variable") %>% #join with the actual estimated parameter values
mutate(class0_sig = case_when((class0_LB_0.025 > 0.5) |                                    (0.5 > class0_UB_0.975) ~ "significant",
.default = "not_significant" ), #significance class 0
class1_sig = case_when((class1_LB_0.025 > 0.5) |                                    (0.5 > class1_UB_0.975) ~ "significant",
.default = "not_significant"), #significance class 1
class2_sig = case_when((class2_LB_0.025 > 0.5) |                                    (0.5 > class2_UB_0.975) ~ "significant",
.default = "not_significant" )) %>% #significance class 2
relocate(variable, contains("class0"), contains("class1"), contains("class2")) #nicely order the dataframe
#| label: CI_mixture_f
#compute 95% CI for mixture parameters
CI_mixture_f <- bootstrapped_params_f %>%
filter(model_name == "class_weights") %>% #filter mixture parameters
select(class_no, value) %>% #select necessary variables
group_by(class_no) %>% #group_by classes
summarise(LB = quantile(value, probs=c(0.025, 0.975))[1], #get bounds of CIs
UB = quantile(value, probs=c(0.025, 0.975))[2])
#Point estimates for OddsRatios
OR_f <- sm_params_f %>%
rename("social"="class0_parameter", "mating" ="class1_parameter", "multiple"="class2_parameter") %>%
mutate(across(all_of(c("social", "mating", "multiple")), ~.x/(1-.x), .names = "Odds_{col}")) %>%
mutate(OR_multiple_mating = Odds_multiple/Odds_mating,
OR_multiple_social = Odds_multiple/Odds_social,
OR_mating_social = Odds_mating/Odds_social) %>%
select(variable, starts_with("OR"))
#Bootstrapped CIs for Odds Ratios
CI_OR_f <- sm_boot_params_f %>%
mutate(boot_id = rep(1:500,sm_boot_params_f %>%
select(class_no, variable) %>%
n_distinct()), #create an id column that makes it possibel to find every bootstrapping iteration
odds = value/(1-value)) %>% #compute odds from the probability values
select(-value) %>%
pivot_wider(names_from = class_no, values_from = odds) %>% #get a wider dataframe for OR computations
rename(social="0", mating ="1", multiple="2") %>% #rename columns for better understanding
mutate(OR_multiple_mating = multiple/mating, #compute ORs for each bootstrap iteration
OR_multiple_social = multiple/social,
OR_mating_social = mating/social) %>%
select(variable, starts_with("OR")) %>%
group_by(variable) %>% #group by each outcome variable & compute upper and lower limits for each confidence interval
summarise(across(starts_with("OR"),~quantile(.x, probs=c(0.025, 0.975))[1], .names = "LB_{col}"),
across(starts_with("OR"),~quantile(.x, probs=c(0.025, 0.975))[2], .names = "UB_{col}"))
CI_OR_f
write_excel_csv(CI_OR_f %>% mutate(across(contains("OR"), ~round(.x, digits=3))), "C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/women's analysis/CI_OR_f.csv")
